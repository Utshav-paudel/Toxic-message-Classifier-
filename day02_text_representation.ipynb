{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25c34a55",
   "metadata": {},
   "source": [
    "# Building NLP model using different text representation techniques like : \n",
    "* Count vectorizer\n",
    "* Word2Vec\n",
    "* TF-IDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4796d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing require packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e467938",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = r\"C:\\Users\\ASUS\\Desktop\\Ml_DL\\code\\Nlp2llm\\toxic_comment_classifier\\jigsaw-toxic-comment-classification-challenge\\train.csv\\train.csv\"\n",
    "test_data_path = r\"C:\\Users\\ASUS\\Desktop\\Ml_DL\\code\\Nlp2llm\\toxic_comment_classifier\\jigsaw-toxic-comment-classification-challenge\\test.csv\\test.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81b9acec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_data_path)\n",
    "test_df = pd.read_csv(test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3d197d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d200d57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>:If you have a look back at the source, the in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>I don't anonymously edit articles at all.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text\n",
       "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...\n",
       "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...\n",
       "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...\n",
       "3  00017563c3f7919a  :If you have a look back at the source, the in...\n",
       "4  00017695ad8997eb          I don't anonymously edit articles at all."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0187db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'full', '’m', '‘ve', 'third', 'towards', 'therein', 'less', 'each', 'formerly', 'she', 'would', 'be', 'forty', 'hereby', 'nowhere', 'anything', 'nothing', 'using', 'we', 'had', 'none', 'well', 'their', 'elsewhere', 'throughout', 'its', 'does', 'seem', 'hence', 'nobody', 'amount', 'that', 'somehow', 'seeming', 'other', 'last', 'hereupon', 'could', \"'re\", 'now', 'alone', 'meanwhile', 'side', 'give', 'cannot', 'behind', 'the', 'ever', 'no', 'of', 'first', 'upon', 'someone', 'yours', 'make', 'they', 'any', 'fifty', 'while', 'almost', 'hers', 'everyone', \"n't\", 'hundred', 'some', 'due', 'regarding', 'nor', 'i', 'yourselves', 'get', 'others', 'twenty', 'whereas', 'another', 'during', 'hereafter', 'already', 'herself', 'once', 'top', 'whoever', 'unless', \"'ll\", 'along', '‘m', 'her', 'around', 'please', 'neither', 'wherever', '‘d', 'otherwise', 'whom', 'say', 'those', 'too', 'yourself', 'somewhere', 'part', '’d', 'perhaps', 'without', 'our', 'an', 'become', 'him', \"'s\", 'two', 'all', 'same', 'just', 'anywhere', 'been', 'can', 'until', 'more', 'whereby', 'bottom', 'much', 'go', 'am', 'herein', 'itself', 'will', 'he', 'never', 'them', 'there', 'five', 'few', 'n‘t', 'a', 'own', '’ll', 'seems', 'do', 'may', 'made', 'sixty', 'where', 'about', 'has', 'everywhere', 'really', 'something', 'here', 'but', 'even', 'themselves', 'toward', 'is', 'being', 'how', 'though', 'did', \"'d\", 'to', 'thereupon', 'out', 'twelve', '’re', 'beforehand', 'his', 'several', 'amongst', 'former', 'should', 'although', 'used', 'my', 'eleven', 'himself', 'anyway', 'yet', 'for', 'or', 'these', 'sometimes', 'whither', 'also', 'either', 'namely', 'must', 'which', 'every', 'so', 'below', 'onto', 'still', 'ten', 'doing', 'down', 'see', 'and', 'because', 'thence', 'before', 'thereby', 'therefore', 'becomes', 'mine', 'done', 'further', 'across', 'moreover', 'myself', 'than', '’s', 'in', 'are', 'have', 'whether', 'whole', 'became', 'call', 'off', 'keep', 'wherein', 'on', 'above', 'front', 'this', 're', 'serious', 'who', '‘ll', 'fifteen', 'up', 'among', 'ourselves', 'various', 'might', 'between', 'nine', 'together', 'such', 'least', 'you', 'whereafter', 'quite', 'becoming', 'over', 'whenever', 'most', 'thus', 'anyone', 'under', 'within', 'show', 'enough', 'was', 'after', 'via', 'n’t', 'seemed', 'name', 'rather', 'whose', 'four', 'from', 'always', 'everything', 'next', 'whereupon', 'one', 'often', 'ca', 'put', 'except', 'since', \"'m\", 'against', 'why', 'beyond', 'empty', 'however', \"'ve\", 'per', 'indeed', 'it', 'nevertheless', 'take', 'thru', '‘re', 'thereafter', 'if', 'latterly', '’ve', 'latter', 'when', 'back', 'by', 'three', 'six', 'move', 'else', 'mostly', 'many', 'then', 'beside', 'at', 'your', 'sometime', 'as', 'again', 'besides', 'afterwards', 'only', 'eight', '‘s', 'into', 'anyhow', 'very', 'were', 'with', 'us', 'ours', 'through', 'whatever', 'me', 'not', 'both', 'what', 'noone', 'whence'}\n"
     ]
    }
   ],
   "source": [
    "# Load English tokenizer, tagger, parser and NER\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# stopwords doesnot have much meaning so removing them makes data more small and efficient\n",
    "stop_words = nlp.Defaults.stop_words\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9446cc24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "punctuation = string.punctuation\n",
    "print(punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898b65eb",
   "metadata": {},
   "source": [
    "## text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f58c4697",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_preprocessing(sentence):\n",
    "    ' custom preprocessing function'\n",
    "    # tokenization\n",
    "    doc = nlp(sentence)\n",
    "    \n",
    "    # lemmatization : more accurate but slower , convert word to baseform    & normalization\n",
    "    lemma_word = [word.lemma_.lower().strip() for word in doc]\n",
    "    \n",
    "    # removing stopwords and punctation\n",
    "    my_token = [word for word in lemma_word if word not in stop_words and word not in punctuation]\n",
    "    \n",
    "    return my_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3b72fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hellow', 'guy', 'london']\n"
     ]
    }
   ],
   "source": [
    "# testing the preprocessing function we built \n",
    "pre = spacy_preprocessing(\"Hellow guys @ how are you in london !\")\n",
    "print(pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f30237c",
   "metadata": {},
   "source": [
    "## text representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0848092d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using count_vectorizer\n",
    "count_vector = CountVectorizer(tokenizer = spacy_preprocessing)     # using count vectorizer \n",
    "tfidf_vector = TfidfVectorizer(tokenizer = spacy_preprocessing)     # using Term frequency Inverse document frequency vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "72926b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vector.fit_transform([\"hello I am very good  and how are you feeling \"]).toarray() # represent on basis of frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c34eabc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.70710678, 0.70710678]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vector.fit_transform([\"hello here I am doing nlp what about you\"]).toarray()   # represent on basis of term_frequency*inverse_documnent_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b9501e8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['feel', 'good', 'hello'], dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vector.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4e4d6fc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hello': 2, 'good': 1, 'feel': 0}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vector.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae3143a",
   "metadata": {},
   "source": [
    "## prepare datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8c7833f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = train_df['comment_text']         # feature representing comment\n",
    "y_label = train_df['toxic']          # represent label either toxic or not toxic\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_label, test_size = 0.2, stratify=y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cf9813eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression model for classifying toxic or not toxic\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifer = LogisticRegression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "40150f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# converting training and test data in representation vectors\n",
    "X_train_vector = count_vector.fit_transform(X_train)\n",
    "X_test_vector = count_vector.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bf24bb0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training the logistic regression model\n",
    "classifer.fit(X_train_vector,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ecfea8fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score :  0.9571048096506345\n",
      "Precision score :  0.6698267407649559\n",
      "Recall score :  0.8509136212624585\n"
     ]
    }
   ],
   "source": [
    "# evaluating model performance using count vectorizer as text representation\n",
    "predicted = classifer.predict(X_test_vector)\n",
    "print(\"Accuracy score : \",metrics.accuracy_score(predicted,y_test))\n",
    "print(\"Precision score : \",metrics.precision_score(predicted,y_test))\n",
    "print(\"Recall score : \",metrics.recall_score(predicted,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8e28eec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"\\n\\nCongratulations from me as well, use the tools well. \\xa0· talk \"'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[5]         # not toxic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8e628dc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifer.predict(X_test_vector[5]) == 0                    # correct prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "db1a6cf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Personal attacks in Fruit Brute VfD \\n\\nMy apologies if I'm being to critical, but I feel that many of the comments made in the Fruit Brute VfD debate were far from reasonable.  There had to be a more diplomatic way to disagree with 's assertion on the initial sentence than don't lie, it makes you look even more juvenile.... Learn to face up to when you've goofed, it will go a long way in your life  The attacks do to his age certainly border on a personal attack.  Were Bart133 forty, sixty, or eighty, would you have included the comment on how 'juvenile' he is?\\n\\nI don't expect you to apologise to anyone, but I want to make it clear that I consider your comments in this VfD debate inappropriate, and I think their are many members of the community who would agree with me.   talk 06:46, 2005 Feb 7 (UTC)\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9618ea9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to input message and find if it is toxic or not\n",
    "def get_answer(message):\n",
    "    message_vector = count_vector.transform([message])\n",
    "    prediction = classifer.predict(message_vector)\n",
    "    if prediction == 0:\n",
    "        print(\"Not toxic\")\n",
    "    else:\n",
    "        print(\"Toxic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "23d7c062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not toxic\n"
     ]
    }
   ],
   "source": [
    "get_answer(\"Hello you are doing great\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b15f7a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toxic\n"
     ]
    }
   ],
   "source": [
    "get_answer(\"Stupid peace of shit stop deleting my stuff\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
